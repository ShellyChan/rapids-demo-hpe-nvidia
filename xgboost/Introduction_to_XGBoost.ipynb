{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## Introduction to XGBoost\n",
    "#### Originally By Paul Hendricks\n",
    "##### Modified By Ingine Hmwe\n",
    "-------\n",
    "\n",
    "In this notebook, we will show how to work with GPU accelerated XGBoost in RAPIDS.\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "* [Introduction to XGBoost](#introduction)\n",
    "* [Setup](#setup)\n",
    "* [Load Libraries](#libraries)\n",
    "* [Generate Data](#generate)\n",
    "  * [Load Data](#load)\n",
    "  * [Simulate Data](#simulate)\n",
    "  * [Split Data](#split)\n",
    "  * [Check Dimensions](#check)\n",
    "* [Convert NumPy data to DMatrix format](#convert)\n",
    "* [Set Parameters](#parameters)\n",
    "* [Train Model](#train)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Setup\n",
    "\n",
    "This notebook was tested using the following Docker containers:\n",
    "\n",
    "* `rapidsai/rapidsai:0.10-cuda10.0-runtime-ubuntu18.04` container from [DockerHub](https://hub.docker.com/r/rapidsai/rapidsai/tags)\n",
    "\n",
    "This notebook was run on the NVIDIA V100 GPU. Please be aware that your system may be different and you may need to modify the code or install packages to run the below examples. \n",
    "\n",
    "Before we begin, let's check out our hardware setup by running the `nvidia-smi` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:38.237293Z",
     "start_time": "2018-11-06T21:03:37.388285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 15 05:00:21 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   37C    P0    37W / 250W |   2028MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:00:09.0 Off |                    0 |\n",
      "| N/A   35C    P0    37W / 250W |    696MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"libraries\"></a>\n",
    "## Load Libraries\n",
    "\n",
    "Let's load some of the libraries within the RAPIDs ecosystem and see which versions we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:41.067879Z",
     "start_time": "2018-11-06T21:03:40.256654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy Version: 1.16.4\n",
      "pandas Version: 0.24.2\n",
      "Scikit-Learn Version: 0.21.3\n",
      "XGBoost Version: 1.0.0-SNAPSHOT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; print('numpy Version:', np.__version__)\n",
    "import pandas as pd; print('pandas Version:', pd.__version__)\n",
    "import sklearn; print('Scikit-Learn Version:', sklearn.__version__)\n",
    "import xgboost as xgb; print('XGBoost Version:', xgb.__version__)\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generate\"></a>\n",
    "## Generate Data\n",
    "\n",
    "<a id=\"load\"></a>\n",
    "### Load Data\n",
    "\n",
    "We can load the data using `cudf.read_csv`. We've provided a helper function `load_data` that will load data from a CSV file (and will only read the first 1 billion rows if that file is unreasonably big)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for loading data\n",
    "def load_data(filename, n_rows):\n",
    "    if n_rows >= 1e9:\n",
    "        gdf = cudf.read_csv(filename)\n",
    "    else:\n",
    "        gdf = cudf.read_csv(filename, nrows=n_rows)\n",
    "    return gdf.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"simulate\"></a>\n",
    "### Simulate Data\n",
    "\n",
    "Alternatively, we can simulate data for our train and validation datasets. The features will be tabular with `n_rows` and `n_columns` in the training dataset, where each value is either of type `np.float32`. We can simulate data for both classification and regression using the `make_classification` or `make_regression` functions from the Scikit-Learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "\n",
    "# helper function for simulating data\n",
    "def simulate_data(m, n, k=2, random_state=None, classification=True):\n",
    "    if classification:\n",
    "        features, labels = make_classification(n_samples=m, n_features=n, \n",
    "                                               n_informative=int(n/5), n_classes=k, \n",
    "                                              random_state=random_state)\n",
    "    else:\n",
    "        features, labels = make_regression(n_samples=m, n_features=n, \n",
    "                                           n_informative=int(n/5), n_targets=1, \n",
    "                                           random_state=random_state)\n",
    "    return np.c_[labels, features].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "simulate = True\n",
    "classification = True  # change this to false to use regression\n",
    "n_rows = int(1e6)  # we'll use 1 millions rows\n",
    "n_columns = int(100)\n",
    "n_categories = 2\n",
    "random_state = np.random.RandomState(43210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 101)\n",
      "CPU times: user 14.9 s, sys: 13 s, total: 27.9 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_file = './simulated_data'\n",
    "\n",
    "if simulate:\n",
    "    dataset = simulate_data(n_rows, n_columns, n_categories, \n",
    "                            random_state=random_state, \n",
    "                            classification=classification)\n",
    "else:\n",
    "    dataset = load_data(data_file, n_rows)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset is a `2D Array` of data, with dataset[0][0] represents `label` and dataset[0][1:end] represents `features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.7669604 ,  0.41350517, ..., -0.8127142 ,\n",
       "        -0.11832006,  0.03517063],\n",
       "       [ 1.        ,  0.03652514, -0.5934094 , ...,  0.32232106,\n",
       "        -0.12324404,  2.4050565 ],\n",
       "       [ 0.        , -0.4764251 ,  1.5536602 , ..., -0.0919623 ,\n",
       "         1.7981887 ,  0.31243178],\n",
       "       ...,\n",
       "       [ 1.        , -1.3806853 , -0.96609867, ..., -1.8649141 ,\n",
       "         0.8573347 ,  1.2853271 ],\n",
       "       [ 1.        ,  1.0025431 , -0.48246416, ...,  0.12920411,\n",
       "         0.03204911,  0.53436947],\n",
       "       [ 1.        , -0.20219818, -0.7586921 , ..., -0.9084102 ,\n",
       "         1.40354   ,  2.0290613 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"split\"></a>\n",
    "### Split Data\n",
    "\n",
    "We'll split our dataset into a 80% training dataset and a 20% validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify shape and indices\n",
    "n_rows, n_columns = dataset.shape\n",
    "train_size = 0.80\n",
    "train_index = int(n_rows * train_size)\n",
    "\n",
    "# split X, y\n",
    "X, y = dataset[:, 1:], dataset[:, 0]\n",
    "del dataset\n",
    "\n",
    "# split train data\n",
    "X_train, y_train = X[:train_index, :], y[:train_index]\n",
    "\n",
    "# split validation data\n",
    "X_validation, y_validation = X[train_index:, :], y[train_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"check\"></a>\n",
    "### Check Dimensions\n",
    "\n",
    "We can check the dimensions and proportions of our training and validation dataets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (800000, 100) float32 y_train:  (800000,) float32\n",
      "X_validation (200000, 100) float32 y_validation:  (200000,) float32\n",
      "X_train proportion: 0.8\n",
      "X_validation proportion: 0.2\n"
     ]
    }
   ],
   "source": [
    "# check dimensions\n",
    "print('X_train: ', X_train.shape, X_train.dtype, 'y_train: ', y_train.shape, y_train.dtype)\n",
    "print('X_validation', X_validation.shape, X_validation.dtype, 'y_validation: ', y_validation.shape, y_validation.dtype)\n",
    "\n",
    "# check the proportions\n",
    "total = X_train.shape[0] + X_validation.shape[0]\n",
    "print('X_train proportion:', X_train.shape[0] / total)\n",
    "print('X_validation proportion:', X_validation.shape[0] / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"convert\"></a>\n",
    "## Convert NumPy data to DMatrix format\n",
    "\n",
    "With our data loaded and formatted as NumPy arrays, our next step is to convert this to a `DMatrix` object that XGBoost can work with. We can instantiate an object of the `xgboost.DMatrix` by passing in the feature matrix as the first argument followed by the label vector using the `label=` keyword argument. To learn more about XGBoost's support for data structures other than NumPy arrays, see the documentation for the Data Interface:\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/python/python_intro.html#data-interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:55.278322Z",
     "start_time": "2018-11-06T21:03:54.059643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.6/site-packages/xgboost/core.py:746: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 956 ms, sys: 765 ms, total: 1.72 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalidation = xgb.DMatrix(X_validation, label=y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"parameters\"></a>\n",
    "## Set Parameters\n",
    "\n",
    "There are a number of parameters that can be set before XGBoost can be run. \n",
    "\n",
    "* General parameters relate to which booster we are using to do boosting, commonly tree or linear model\n",
    "* Booster parameters depend on which booster you have chosen\n",
    "* Learning task parameters decide on the learning scenario. For example, regression tasks may use different parameters with ranking tasks.\n",
    "\n",
    "For more information on the configurable parameters within the XGBoost module, see the documentation here:\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:57.443698Z",
     "start_time": "2018-11-06T21:03:57.438288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbosity': 0, 'max_depth': 6, 'tree_method': 'gpu_hist', 'n_gpus': 1, 'eval_metric': 'auc', 'objective': 'binary:logistic'}\n"
     ]
    }
   ],
   "source": [
    "'''instantiate GPU PARAMS '''\n",
    "paramsGPU = {}\n",
    "\n",
    "# general params\n",
    "general_params = {'verbosity': 0}\n",
    "paramsGPU.update(general_params)\n",
    "\n",
    "# booster params\n",
    "n_gpus = 1  # change this to -1 to use all GPUs available or 0 to use the CPU\n",
    "booster_params = {}\n",
    "\n",
    "# gpu implementation of hist algorithm\n",
    "if n_gpus != 0:\n",
    "    booster_params['max_depth'] = 6\n",
    "    booster_params['tree_method'] = 'gpu_hist'\n",
    "    booster_params['n_gpus'] = n_gpus   \n",
    "paramsGPU.update(booster_params)\n",
    "\n",
    "# learning task params\n",
    "learning_task_params = {}\n",
    "if classification:\n",
    "    learning_task_params['eval_metric'] = 'auc'\n",
    "    learning_task_params['objective'] = 'binary:logistic'\n",
    "else:\n",
    "    learning_task_params['eval_metric'] = 'rmse'\n",
    "    learning_task_params['objective'] = 'reg:squarederror'\n",
    "paramsGPU.update(learning_task_params)\n",
    "\n",
    "print(paramsGPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'max_depth': 6, 'tree_method': 'hist', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'n_jobs': 32}\n"
     ]
    }
   ],
   "source": [
    "'''instantiate CPU PARAMS '''\n",
    "\n",
    "nCores = !nproc --all\n",
    "nCores = int(nCores[0])\n",
    "\n",
    "cpu_num_round = 100\n",
    "\n",
    "paramsCPU = {\n",
    "    'n_estimators': cpu_num_round,\n",
    "    'max_depth': 6,\n",
    "    'tree_method': 'hist',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'n_jobs': nCores\n",
    "}\n",
    "\n",
    "print(paramsCPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## Train Model\n",
    "\n",
    "Now it's time to train our model! We can use the `xgb.train` function and pass in the parameters, training dataset, the number of boosting iterations, and the list of items to be evaluated during training. For more information on the parameters that can be passed into `xgb.train`, check out the documentation:\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training settings\n",
    "evallist = [(dvalidation, 'validation'), (dtrain, 'train')]\n",
    "gpu_num_round = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:04:50.201308Z",
     "start_time": "2018-11-06T21:04:00.363740Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:00:35] WARNING: /conda/conda-bld/xgboost_1571337743864/work/include/xgboost/generic_parameters.h:28: \n",
      "n_gpus: \n",
      "\tDeprecated. Single process multi-GPU training is no longer supported.\n",
      "\tPlease switch to distributed training with one process per GPU.\n",
      "\tThis can be done using Dask or Spark.  See documentation for details.\n",
      "[0]\tvalidation-auc:0.89143\ttrain-auc:0.89310\n",
      "[1]\tvalidation-auc:0.91929\ttrain-auc:0.92058\n",
      "[2]\tvalidation-auc:0.93920\ttrain-auc:0.94055\n",
      "[3]\tvalidation-auc:0.94835\ttrain-auc:0.94974\n",
      "[4]\tvalidation-auc:0.95581\ttrain-auc:0.95714\n",
      "[5]\tvalidation-auc:0.96042\ttrain-auc:0.96177\n",
      "[6]\tvalidation-auc:0.96489\ttrain-auc:0.96612\n",
      "[7]\tvalidation-auc:0.96865\ttrain-auc:0.96981\n",
      "[8]\tvalidation-auc:0.97128\ttrain-auc:0.97245\n",
      "[9]\tvalidation-auc:0.97415\ttrain-auc:0.97533\n",
      "[10]\tvalidation-auc:0.97564\ttrain-auc:0.97680\n",
      "[11]\tvalidation-auc:0.97797\ttrain-auc:0.97917\n",
      "[12]\tvalidation-auc:0.97891\ttrain-auc:0.98010\n",
      "[13]\tvalidation-auc:0.98000\ttrain-auc:0.98113\n",
      "[14]\tvalidation-auc:0.98075\ttrain-auc:0.98188\n",
      "[15]\tvalidation-auc:0.98203\ttrain-auc:0.98318\n",
      "[16]\tvalidation-auc:0.98269\ttrain-auc:0.98383\n",
      "[17]\tvalidation-auc:0.98310\ttrain-auc:0.98424\n",
      "[18]\tvalidation-auc:0.98398\ttrain-auc:0.98510\n",
      "[19]\tvalidation-auc:0.98450\ttrain-auc:0.98562\n",
      "[20]\tvalidation-auc:0.98506\ttrain-auc:0.98616\n",
      "[21]\tvalidation-auc:0.98580\ttrain-auc:0.98686\n",
      "[22]\tvalidation-auc:0.98614\ttrain-auc:0.98717\n",
      "[23]\tvalidation-auc:0.98637\ttrain-auc:0.98739\n",
      "[24]\tvalidation-auc:0.98659\ttrain-auc:0.98761\n",
      "[25]\tvalidation-auc:0.98734\ttrain-auc:0.98830\n",
      "[26]\tvalidation-auc:0.98775\ttrain-auc:0.98867\n",
      "[27]\tvalidation-auc:0.98802\ttrain-auc:0.98894\n",
      "[28]\tvalidation-auc:0.98827\ttrain-auc:0.98918\n",
      "[29]\tvalidation-auc:0.98875\ttrain-auc:0.98963\n",
      "[30]\tvalidation-auc:0.98900\ttrain-auc:0.98989\n",
      "[31]\tvalidation-auc:0.98938\ttrain-auc:0.99025\n",
      "[32]\tvalidation-auc:0.98954\ttrain-auc:0.99040\n",
      "[33]\tvalidation-auc:0.98962\ttrain-auc:0.99049\n",
      "[34]\tvalidation-auc:0.98987\ttrain-auc:0.99072\n",
      "[35]\tvalidation-auc:0.98994\ttrain-auc:0.99080\n",
      "[36]\tvalidation-auc:0.99009\ttrain-auc:0.99096\n",
      "[37]\tvalidation-auc:0.99035\ttrain-auc:0.99121\n",
      "[38]\tvalidation-auc:0.99059\ttrain-auc:0.99144\n",
      "[39]\tvalidation-auc:0.99067\ttrain-auc:0.99154\n",
      "[40]\tvalidation-auc:0.99068\ttrain-auc:0.99158\n",
      "[41]\tvalidation-auc:0.99072\ttrain-auc:0.99164\n",
      "[42]\tvalidation-auc:0.99090\ttrain-auc:0.99180\n",
      "[43]\tvalidation-auc:0.99100\ttrain-auc:0.99190\n",
      "[44]\tvalidation-auc:0.99116\ttrain-auc:0.99206\n",
      "[45]\tvalidation-auc:0.99118\ttrain-auc:0.99209\n",
      "[46]\tvalidation-auc:0.99123\ttrain-auc:0.99216\n",
      "[47]\tvalidation-auc:0.99142\ttrain-auc:0.99233\n",
      "[48]\tvalidation-auc:0.99145\ttrain-auc:0.99238\n",
      "[49]\tvalidation-auc:0.99148\ttrain-auc:0.99242\n",
      "[50]\tvalidation-auc:0.99152\ttrain-auc:0.99247\n",
      "[51]\tvalidation-auc:0.99162\ttrain-auc:0.99257\n",
      "[52]\tvalidation-auc:0.99166\ttrain-auc:0.99262\n",
      "[53]\tvalidation-auc:0.99169\ttrain-auc:0.99267\n",
      "[54]\tvalidation-auc:0.99181\ttrain-auc:0.99280\n",
      "[55]\tvalidation-auc:0.99182\ttrain-auc:0.99283\n",
      "[56]\tvalidation-auc:0.99188\ttrain-auc:0.99289\n",
      "[57]\tvalidation-auc:0.99194\ttrain-auc:0.99297\n",
      "[58]\tvalidation-auc:0.99202\ttrain-auc:0.99305\n",
      "[59]\tvalidation-auc:0.99216\ttrain-auc:0.99319\n",
      "[60]\tvalidation-auc:0.99225\ttrain-auc:0.99328\n",
      "[61]\tvalidation-auc:0.99230\ttrain-auc:0.99334\n",
      "[62]\tvalidation-auc:0.99232\ttrain-auc:0.99337\n",
      "[63]\tvalidation-auc:0.99243\ttrain-auc:0.99348\n",
      "[64]\tvalidation-auc:0.99252\ttrain-auc:0.99357\n",
      "[65]\tvalidation-auc:0.99257\ttrain-auc:0.99363\n",
      "[66]\tvalidation-auc:0.99267\ttrain-auc:0.99373\n",
      "[67]\tvalidation-auc:0.99269\ttrain-auc:0.99376\n",
      "[68]\tvalidation-auc:0.99272\ttrain-auc:0.99379\n",
      "[69]\tvalidation-auc:0.99273\ttrain-auc:0.99382\n",
      "[70]\tvalidation-auc:0.99276\ttrain-auc:0.99386\n",
      "[71]\tvalidation-auc:0.99281\ttrain-auc:0.99391\n",
      "[72]\tvalidation-auc:0.99285\ttrain-auc:0.99395\n",
      "[73]\tvalidation-auc:0.99288\ttrain-auc:0.99399\n",
      "[74]\tvalidation-auc:0.99293\ttrain-auc:0.99403\n",
      "[75]\tvalidation-auc:0.99300\ttrain-auc:0.99410\n",
      "[76]\tvalidation-auc:0.99311\ttrain-auc:0.99420\n",
      "[77]\tvalidation-auc:0.99321\ttrain-auc:0.99428\n",
      "[78]\tvalidation-auc:0.99328\ttrain-auc:0.99435\n",
      "[79]\tvalidation-auc:0.99331\ttrain-auc:0.99440\n",
      "[80]\tvalidation-auc:0.99333\ttrain-auc:0.99442\n",
      "[81]\tvalidation-auc:0.99334\ttrain-auc:0.99445\n",
      "[82]\tvalidation-auc:0.99336\ttrain-auc:0.99448\n",
      "[83]\tvalidation-auc:0.99336\ttrain-auc:0.99449\n",
      "[84]\tvalidation-auc:0.99337\ttrain-auc:0.99451\n",
      "[85]\tvalidation-auc:0.99337\ttrain-auc:0.99454\n",
      "[86]\tvalidation-auc:0.99342\ttrain-auc:0.99459\n",
      "[87]\tvalidation-auc:0.99347\ttrain-auc:0.99465\n",
      "[88]\tvalidation-auc:0.99349\ttrain-auc:0.99467\n",
      "[89]\tvalidation-auc:0.99356\ttrain-auc:0.99473\n",
      "[90]\tvalidation-auc:0.99360\ttrain-auc:0.99477\n",
      "[91]\tvalidation-auc:0.99362\ttrain-auc:0.99480\n",
      "[92]\tvalidation-auc:0.99362\ttrain-auc:0.99482\n",
      "[93]\tvalidation-auc:0.99362\ttrain-auc:0.99484\n",
      "[94]\tvalidation-auc:0.99363\ttrain-auc:0.99487\n",
      "[95]\tvalidation-auc:0.99367\ttrain-auc:0.99491\n",
      "[96]\tvalidation-auc:0.99371\ttrain-auc:0.99496\n",
      "[97]\tvalidation-auc:0.99375\ttrain-auc:0.99500\n",
      "[98]\tvalidation-auc:0.99377\ttrain-auc:0.99503\n",
      "[99]\tvalidation-auc:0.99379\ttrain-auc:0.99507\n",
      "CPU times: user 1min 6s, sys: 1.06 s, total: 1min 7s\n",
      "Wall time: 6.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gpu_bst = xgb.train(paramsGPU, dtrain, gpu_num_round, evallist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46 µs, sys: 10 µs, total: 56 µs\n",
      "Wall time: 60.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cpu_bst = xgb.XGBClassifier(n_estimators = paramsCPU['n_estimators'],\n",
    "                                tree_method = paramsCPU['tree_method'],\n",
    "                                objective = paramsCPU['objective'],\n",
    "                                n_jobs = paramsCPU['n_jobs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.80024\tvalidation_1-auc:0.80026\n",
      "[1]\tvalidation_0-auc:0.81536\tvalidation_1-auc:0.81527\n",
      "[2]\tvalidation_0-auc:0.84754\tvalidation_1-auc:0.84779\n",
      "[3]\tvalidation_0-auc:0.85908\tvalidation_1-auc:0.85930\n",
      "[4]\tvalidation_0-auc:0.86482\tvalidation_1-auc:0.86532\n",
      "[5]\tvalidation_0-auc:0.86835\tvalidation_1-auc:0.86877\n",
      "[6]\tvalidation_0-auc:0.87200\tvalidation_1-auc:0.87237\n",
      "[7]\tvalidation_0-auc:0.87644\tvalidation_1-auc:0.87707\n",
      "[8]\tvalidation_0-auc:0.88128\tvalidation_1-auc:0.88209\n",
      "[9]\tvalidation_0-auc:0.88544\tvalidation_1-auc:0.88635\n",
      "[10]\tvalidation_0-auc:0.88760\tvalidation_1-auc:0.88862\n",
      "[11]\tvalidation_0-auc:0.89376\tvalidation_1-auc:0.89494\n",
      "[12]\tvalidation_0-auc:0.89780\tvalidation_1-auc:0.89909\n",
      "[13]\tvalidation_0-auc:0.90027\tvalidation_1-auc:0.90153\n",
      "[14]\tvalidation_0-auc:0.90407\tvalidation_1-auc:0.90518\n",
      "[15]\tvalidation_0-auc:0.90748\tvalidation_1-auc:0.90854\n",
      "[16]\tvalidation_0-auc:0.91069\tvalidation_1-auc:0.91182\n",
      "[17]\tvalidation_0-auc:0.91273\tvalidation_1-auc:0.91391\n",
      "[18]\tvalidation_0-auc:0.91540\tvalidation_1-auc:0.91652\n",
      "[19]\tvalidation_0-auc:0.91914\tvalidation_1-auc:0.92020\n",
      "[20]\tvalidation_0-auc:0.92188\tvalidation_1-auc:0.92303\n",
      "[21]\tvalidation_0-auc:0.92343\tvalidation_1-auc:0.92460\n",
      "[22]\tvalidation_0-auc:0.92578\tvalidation_1-auc:0.92698\n",
      "[23]\tvalidation_0-auc:0.92763\tvalidation_1-auc:0.92884\n",
      "[24]\tvalidation_0-auc:0.92826\tvalidation_1-auc:0.92947\n",
      "[25]\tvalidation_0-auc:0.92961\tvalidation_1-auc:0.93081\n",
      "[26]\tvalidation_0-auc:0.93193\tvalidation_1-auc:0.93319\n",
      "[27]\tvalidation_0-auc:0.93344\tvalidation_1-auc:0.93466\n",
      "[28]\tvalidation_0-auc:0.93450\tvalidation_1-auc:0.93570\n",
      "[29]\tvalidation_0-auc:0.93537\tvalidation_1-auc:0.93656\n",
      "[30]\tvalidation_0-auc:0.93699\tvalidation_1-auc:0.93815\n",
      "[31]\tvalidation_0-auc:0.93807\tvalidation_1-auc:0.93927\n",
      "[32]\tvalidation_0-auc:0.93976\tvalidation_1-auc:0.94100\n",
      "[33]\tvalidation_0-auc:0.94158\tvalidation_1-auc:0.94282\n",
      "[34]\tvalidation_0-auc:0.94285\tvalidation_1-auc:0.94403\n",
      "[35]\tvalidation_0-auc:0.94352\tvalidation_1-auc:0.94465\n",
      "[36]\tvalidation_0-auc:0.94372\tvalidation_1-auc:0.94486\n",
      "[37]\tvalidation_0-auc:0.94495\tvalidation_1-auc:0.94612\n",
      "[38]\tvalidation_0-auc:0.94574\tvalidation_1-auc:0.94689\n",
      "[39]\tvalidation_0-auc:0.94696\tvalidation_1-auc:0.94812\n",
      "[40]\tvalidation_0-auc:0.94760\tvalidation_1-auc:0.94875\n",
      "[41]\tvalidation_0-auc:0.94815\tvalidation_1-auc:0.94931\n",
      "[42]\tvalidation_0-auc:0.94905\tvalidation_1-auc:0.95022\n",
      "[43]\tvalidation_0-auc:0.95004\tvalidation_1-auc:0.95120\n",
      "[44]\tvalidation_0-auc:0.95056\tvalidation_1-auc:0.95169\n",
      "[45]\tvalidation_0-auc:0.95092\tvalidation_1-auc:0.95208\n",
      "[46]\tvalidation_0-auc:0.95161\tvalidation_1-auc:0.95276\n",
      "[47]\tvalidation_0-auc:0.95227\tvalidation_1-auc:0.95342\n",
      "[48]\tvalidation_0-auc:0.95281\tvalidation_1-auc:0.95397\n",
      "[49]\tvalidation_0-auc:0.95316\tvalidation_1-auc:0.95431\n",
      "[50]\tvalidation_0-auc:0.95385\tvalidation_1-auc:0.95498\n",
      "[51]\tvalidation_0-auc:0.95441\tvalidation_1-auc:0.95551\n",
      "[52]\tvalidation_0-auc:0.95480\tvalidation_1-auc:0.95591\n",
      "[53]\tvalidation_0-auc:0.95516\tvalidation_1-auc:0.95627\n",
      "[54]\tvalidation_0-auc:0.95555\tvalidation_1-auc:0.95664\n",
      "[55]\tvalidation_0-auc:0.95608\tvalidation_1-auc:0.95715\n",
      "[56]\tvalidation_0-auc:0.95619\tvalidation_1-auc:0.95727\n",
      "[57]\tvalidation_0-auc:0.95666\tvalidation_1-auc:0.95773\n",
      "[58]\tvalidation_0-auc:0.95686\tvalidation_1-auc:0.95793\n",
      "[59]\tvalidation_0-auc:0.95725\tvalidation_1-auc:0.95833\n",
      "[60]\tvalidation_0-auc:0.95772\tvalidation_1-auc:0.95880\n",
      "[61]\tvalidation_0-auc:0.95808\tvalidation_1-auc:0.95913\n",
      "[62]\tvalidation_0-auc:0.95836\tvalidation_1-auc:0.95943\n",
      "[63]\tvalidation_0-auc:0.95874\tvalidation_1-auc:0.95981\n",
      "[64]\tvalidation_0-auc:0.95895\tvalidation_1-auc:0.96002\n",
      "[65]\tvalidation_0-auc:0.95919\tvalidation_1-auc:0.96027\n",
      "[66]\tvalidation_0-auc:0.95949\tvalidation_1-auc:0.96054\n",
      "[67]\tvalidation_0-auc:0.95973\tvalidation_1-auc:0.96078\n",
      "[68]\tvalidation_0-auc:0.96035\tvalidation_1-auc:0.96139\n",
      "[69]\tvalidation_0-auc:0.96093\tvalidation_1-auc:0.96196\n",
      "[70]\tvalidation_0-auc:0.96115\tvalidation_1-auc:0.96219\n",
      "[71]\tvalidation_0-auc:0.96146\tvalidation_1-auc:0.96247\n",
      "[72]\tvalidation_0-auc:0.96189\tvalidation_1-auc:0.96289\n",
      "[73]\tvalidation_0-auc:0.96215\tvalidation_1-auc:0.96315\n",
      "[74]\tvalidation_0-auc:0.96265\tvalidation_1-auc:0.96365\n",
      "[75]\tvalidation_0-auc:0.96291\tvalidation_1-auc:0.96389\n",
      "[76]\tvalidation_0-auc:0.96328\tvalidation_1-auc:0.96425\n",
      "[77]\tvalidation_0-auc:0.96350\tvalidation_1-auc:0.96446\n",
      "[78]\tvalidation_0-auc:0.96403\tvalidation_1-auc:0.96498\n",
      "[79]\tvalidation_0-auc:0.96419\tvalidation_1-auc:0.96515\n",
      "[80]\tvalidation_0-auc:0.96461\tvalidation_1-auc:0.96557\n",
      "[81]\tvalidation_0-auc:0.96486\tvalidation_1-auc:0.96581\n",
      "[82]\tvalidation_0-auc:0.96493\tvalidation_1-auc:0.96588\n",
      "[83]\tvalidation_0-auc:0.96514\tvalidation_1-auc:0.96609\n",
      "[84]\tvalidation_0-auc:0.96529\tvalidation_1-auc:0.96622\n",
      "[85]\tvalidation_0-auc:0.96569\tvalidation_1-auc:0.96661\n",
      "[86]\tvalidation_0-auc:0.96628\tvalidation_1-auc:0.96718\n",
      "[87]\tvalidation_0-auc:0.96662\tvalidation_1-auc:0.96752\n",
      "[88]\tvalidation_0-auc:0.96687\tvalidation_1-auc:0.96777\n",
      "[89]\tvalidation_0-auc:0.96710\tvalidation_1-auc:0.96799\n",
      "[90]\tvalidation_0-auc:0.96744\tvalidation_1-auc:0.96831\n",
      "[91]\tvalidation_0-auc:0.96758\tvalidation_1-auc:0.96844\n",
      "[92]\tvalidation_0-auc:0.96786\tvalidation_1-auc:0.96871\n",
      "[93]\tvalidation_0-auc:0.96800\tvalidation_1-auc:0.96885\n",
      "[94]\tvalidation_0-auc:0.96814\tvalidation_1-auc:0.96898\n",
      "[95]\tvalidation_0-auc:0.96847\tvalidation_1-auc:0.96930\n",
      "[96]\tvalidation_0-auc:0.96858\tvalidation_1-auc:0.96941\n",
      "[97]\tvalidation_0-auc:0.96871\tvalidation_1-auc:0.96953\n",
      "[98]\tvalidation_0-auc:0.96889\tvalidation_1-auc:0.96971\n",
      "[99]\tvalidation_0-auc:0.96898\tvalidation_1-auc:0.96979\n",
      "CPU times: user 4min 56s, sys: 3.33 s, total: 5min\n",
      "Wall time: 15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=32,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='hist',\n",
       "              verbosity=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cpu_bst.fit(X_train, y_train,\n",
    "        eval_set=[(X_validation, y_validation), (X_train, y_train)],\n",
    "        eval_metric=paramsCPU['eval_metric'],\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_result = cpu_bst.evals_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we showed how to work with GPU accelerated XGBoost in RAPIDS.\n",
    "\n",
    "To learn more about RAPIDS, be sure to check out: \n",
    "\n",
    "* [Open Source Website](http://rapids.ai)\n",
    "* [GitHub](https://github.com/rapidsai/)\n",
    "* [Press Release](https://nvidianews.nvidia.com/news/nvidia-introduces-rapids-open-source-gpu-acceleration-platform-for-large-scale-data-analytics-and-machine-learning)\n",
    "* [NVIDIA Blog](https://blogs.nvidia.com/blog/2018/10/10/rapids-data-science-open-source-community/)\n",
    "* [Developer Blog](https://devblogs.nvidia.com/gpu-accelerated-analytics-rapids/)\n",
    "* [NVIDIA Data Science Webpage](https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits go to Paul Hendricks for authoring and creating this notebook\n",
    "* https://github.com/rapidsai/notebooks-contrib/blob/master/getting_started_notebooks/intro_tutorials/07_Introduction_to_XGBoost.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
